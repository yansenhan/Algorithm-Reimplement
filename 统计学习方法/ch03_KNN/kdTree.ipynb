{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch3 kd-Tree KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author: Aiden Yansen Han\n",
    "- Date: July 14, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Notes of kd-tree KNN:**\n",
    "- kd-tree KNN only needs O(log n) computational time.\n",
    "- kd Tree is binary.\n",
    "- The choice of k is determined by cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The code for kd-tree KNN:**\n",
    "- The code can be divided into two parts. \n",
    "- The first part is to construct a kd tree. \n",
    "- The second part is to implement KNN algorithm under the kd-tree data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### kd-tree construction\n",
    "import numpy as np\n",
    "\n",
    "class kdTreeNode():\n",
    "    def __init__(self, data, label=0, cut_axis=0, flag=0):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.cut_axis = cut_axis # used for kd-tree KNN and means which axis of data are used to do sorting.\n",
    "        self.flag = 0 # recorded whether this point has been arrived or not.\n",
    "\n",
    "\n",
    "class kdTree():\n",
    "    '''\n",
    "    This class constructs a kd tree for both unlabled data and labeled data.\n",
    "    \n",
    "    Parameter:\n",
    "    -- samples: an array or a list(can be high-dimension)\n",
    "    -- lables: an array or a list or None\n",
    "    '''    \n",
    "    def __init__(self, samples, labels=None):\n",
    "        self.root = None\n",
    "        self.samples = samples\n",
    "        self.labels = labels\n",
    "        \n",
    "    def _construct_tree(self, samples, labels=None, index=0):\n",
    "        samples_len = len(samples)\n",
    "        samples_dim = np.array(samples).ndim\n",
    "        labels = np.squeeze(labels) if labels is not None else None\n",
    "        samples = samples if type(samples) == list else samples.tolist()\n",
    "        if labels is not None:\n",
    "            labels = labels if type(labels) == list else labels.tolist()\n",
    "        if samples_len == 1:\n",
    "            return kdTreeNode(np.squeeze(samples).tolist(), labels, index)\n",
    "        elif samples_len == 0:\n",
    "            return None\n",
    "\n",
    "        samples.sort(key = lambda x: x[index])\n",
    "        median_point = samples_len//2\n",
    "        root_data = samples[median_point]\n",
    "        root_label = labels[median_point] if labels is not None else None\n",
    "        root = kdTreeNode(root_data, root_label, index)\n",
    "\n",
    "        idx = (index + 1) % samples_dim\n",
    "        if labels is None:\n",
    "            root.left = self._construct_tree(samples[:median_point], None, idx)\n",
    "            root.right = self._construct_tree(samples[median_point+1:], None, idx)\n",
    "        else:\n",
    "            root.left = self._construct_tree(samples[:median_point], labels[:median_point], idx)\n",
    "            root.right = self._construct_tree(samples[median_point+1:], labels[median_point+1:], idx)\n",
    "\n",
    "        return np.squeeze(root).tolist()\n",
    "    \n",
    "    def construct_kdTree(self):\n",
    "        self.root = self._construct_tree(self.samples, self.labels)\n",
    "        return self.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    '''\n",
    "    This KNN class would contain two methods, simple KNN and kd-tree KNN.\n",
    "    \n",
    "    Parameters:\n",
    "    -- X_training: an array or list; the feature vectors of training data.\n",
    "    -- Y_training: an array or list; the labels of training data.\n",
    "    -- X_test: an array or list; the feature vectors of test data.\n",
    "    -- p: the order of L^p distance. When p=2, the distance is Euclid distance.\n",
    "    -- k: the count-in number of nearest neighbors.\n",
    "    '''\n",
    "    def __init__(self, X_training, Y_training, X_test, p=2, k=3):\n",
    "        self.X_training = X_training if type(X_training) == list else X_training.tolist()\n",
    "        self.Y_training = Y_training if type(Y_training) == list else Y_training.tolist()\n",
    "        self.X_test = X_test if type(X_test) == list else X_test.tolist()\n",
    "        self.p = p\n",
    "        self.k = k\n",
    "    \n",
    "    def _distance(self, sample, p):\n",
    "        if p == 1:\n",
    "            s = 0\n",
    "            for i in list(sample):\n",
    "                s += abs(i)\n",
    "        elif p == \"inf\":\n",
    "            s = max(list(sample))\n",
    "        else:\n",
    "            s = 0\n",
    "            for i in list(sample):\n",
    "                s += i**p\n",
    "            s = s**(1/p)\n",
    "        return s\n",
    "    \n",
    "    def _get_mode(self, list_data):\n",
    "        output = []\n",
    "        for row in list_data:\n",
    "            counts = np.bincount(row)\n",
    "            output.append(np.argmax(counts))\n",
    "        return output\n",
    "    \n",
    "    def simple_KNN(self):\n",
    "        test_data_len = len(self.X_test)\n",
    "        Y_nearest_neighbor = []\n",
    "        Y_nearest_neighbor_idx = []\n",
    "        Y_nearest_neighbor_dist = []\n",
    "        \n",
    "        for i in range(len(X_training)):\n",
    "            for j in range(test_data_len):\n",
    "                try:\n",
    "                    Ynn_j_len = len(Y_nearest_neighbor_dist[j])\n",
    "                    new_distance = self._distance(np.array(X_training[i])-np.array(X_test[j]), self.p)\n",
    "                    \n",
    "                    if Ynn_j_len >= self.k:                        \n",
    "                        Ynn_j = np.array(Y_nearest_neighbor_dist[j])\n",
    "                        Ynn_j_max = Ynn_j.max()\n",
    "                        if new_distance < Ynn_j_max:\n",
    "                            Ynn_j_argmax = Ynn_j.argmax()\n",
    "                            Y_nearest_neighbor[j][Ynn_j_argmax] = i\n",
    "                            Y_nearest_neighbor_dist[j][Ynn_j_argmax] = new_distance\n",
    "                            Y_nearest_neighbor_idx[j][Ynn_j_argmax] =self.Y_training[i]\n",
    "                    else:\n",
    "                        Y_nearest_neighbor[j].append(i)\n",
    "                        Y_nearest_neighbor_dist[j].append(new_distance)\n",
    "                        Y_nearest_neighbor_idx[j].append(self.Y_training[i])\n",
    "                        \n",
    "                except IndexError:\n",
    "                    Y_nearest_neighbor.append([i])\n",
    "                    Y_nearest_neighbor_idx.append([self.Y_training[i]])\n",
    "                    Y_nearest_neighbor_dist.append([self._distance(np.array(X_training[i])-np.array(X_test[j]), self.p)])\n",
    "        \n",
    "        print(\"The nearest neighbors for each test data are:\\n\")      \n",
    "        for i in Y_nearest_neighbor:\n",
    "            for j in i:\n",
    "                print(X_training[j], '\\n')\n",
    "            print('------')\n",
    "            \n",
    "        print(\"The labels of nearest neighbors are:\", Y_nearest_neighbor_idx)\n",
    "        return self._get_mode(Y_nearest_neighbor_idx)\n",
    "    \n",
    "    ########################################################\n",
    "    ### The following functions are used for kd-tree KNN ###\n",
    "    ########################################################\n",
    "    \n",
    "    def go_to_leaf(self, root, point):\n",
    "        '''\n",
    "        Function for Step 1 of kd-tree KNN\n",
    "        '''\n",
    "        traversal_record = [root]\n",
    "        cut_axis = root.cut_axis\n",
    "        if root.data[cut_axis] > point[cut_axis] and root.left is not None:\n",
    "            traversal_record.extend(self.go_to_leaf(root.left, point))\n",
    "        elif root.data[cut_axis] <= point[cut_axis] and root.right is not None:\n",
    "            traversal_record.extend(self.go_to_leaf(root.right, point))\n",
    "        return traversal_record\n",
    "    \n",
    "    def _add_item(self, leaf, point, nearest_Neighbors):\n",
    "        '''\n",
    "        Function for Step 2 of kd-tree KNN\n",
    "        '''\n",
    "        d = np.shape(nearest_Neighbors)[1] if np.array(nearest_Neighbors).ndim > 1 else 0\n",
    "        new_distance = self._distance(np.array(point)-np.array(leaf.data), self.p)\n",
    "        \n",
    "        if d == 0:\n",
    "            nearest_Neighbors = [[new_distance], [leaf]]\n",
    "        elif d == self.k:\n",
    "            if np.max(nearest_Neighbors[0]) > new_distance:\n",
    "                idx = np.argmax(nearest_Neighbors[0])\n",
    "                nearest_Neighbors[0][idx] = new_distance\n",
    "                nearest_Neighbors[1][idx] = leaf\n",
    "        else:\n",
    "            nearest_Neighbors[0].append(new_distance)\n",
    "            nearest_Neighbors[1].append(leaf)\n",
    "        return nearest_Neighbors\n",
    "    \n",
    "    def _step3_2_step3(self, leaf, root, point, record, nearest_Neighbors):\n",
    "        '''\n",
    "        Function for Step 3 of kd-tree KNN\n",
    "        '''\n",
    "        if leaf is root:\n",
    "            return nearest_Neighbors\n",
    "        else:\n",
    "            leaf = record.pop(-1)\n",
    "            if leaf.flag == 1:\n",
    "                return self._step3_2_step3(leaf, root, point, record, nearest_Neighbors)\n",
    "            else:\n",
    "                leaf.flag = 1\n",
    "                ### step 3.1 ###\n",
    "                nearest_Neighbors = self._add_item(leaf, point, nearest_Neighbors)\n",
    "                ### step 3.2 ###\n",
    "                cut_axis = leaf.cut_axis\n",
    "                distance_from_cutline = abs(leaf.data[cut_axis] - point[cut_axis])\n",
    "                \n",
    "                if distance_from_cutline > np.max(nearest_Neighbors[0]) or leaf.right is None or leaf.left is None:\n",
    "                    \n",
    "                    return self._step3_2_step3(leaf, root, point, record, nearest_Neighbors)\n",
    "                    \n",
    "                else:\n",
    "                    if leaf.left.flag == 1:\n",
    "                        nearest_Neighbors = self.kdTree_KNN_4_single_point(leaf.right, point, nearest_Neighbors)\n",
    "                    else:\n",
    "                        nearest_Neighbors = self.kdTree_KNN_4_single_point(leaf.left, point, nearest_Neighbors)\n",
    "                    return self._step3_2_step3(leaf, root, point, record, nearest_Neighbors)\n",
    "    \n",
    "    def kdTree_KNN_4_single_point(self, root, point, nearest_Neighbors=[]):\n",
    "        \n",
    "        ### Step 1 ###\n",
    "        record = self.go_to_leaf(root, point)\n",
    "        \n",
    "        ### Step 2 ###\n",
    "        leaf = record.pop(-1)\n",
    "        leaf.flag = 1\n",
    "        nearest_Neighbors = self._add_item(leaf, point, nearest_Neighbors)\n",
    "            \n",
    "        ### Step 3 ###\n",
    "        nearest_Neighbors = self._step3_2_step3(leaf, root, point, record, nearest_Neighbors)\n",
    "        \n",
    "        return nearest_Neighbors\n",
    "    \n",
    "    def kdTree_KNN(self, root_copy, X_test, nearest_Neighbors=[]):\n",
    "        neighbor_labels = []\n",
    "        import copy\n",
    "        print(\"The nearest neighbors for each sample are:\\n\")\n",
    "        for sample in X_test:\n",
    "            root = copy.deepcopy(root_copy)\n",
    "            nearest_Neighbors_4_single_sample = self.kdTree_KNN_4_single_point(root, sample)\n",
    "            neighbor_labels_4_single_sample = []\n",
    "            for node in nearest_Neighbors_4_single_sample[1]:\n",
    "                neighbor_labels_4_single_sample.append(node.label)\n",
    "                print(node.data, '\\n')\n",
    "            print(\"------\")\n",
    "            neighbor_labels.append(neighbor_labels_4_single_sample)\n",
    "            \n",
    "        print(\"The labels of nearest neighbors are:\", neighbor_labels)\n",
    "        return self._get_mode(neighbor_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments\n",
    "**1. Synthetic Data For Examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some data on a plane. For those y>x, we label it as 1; otherwise, we label it as 0.\n",
    "np.random.seed(1010)\n",
    "X_training = np.random.rand(10, 2).tolist()\n",
    "Y_training = [(1 if i[0] < i[1] else 0) for i in np.random.randn(10, 2).tolist()]\n",
    "X_test = [[0.7,0.9], [0.3, 0.1], [0.8, 0.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.3942564861172032, 0.1755924719507771],\n",
       " [0.07270586036662141, 0.19188086780745994],\n",
       " [0.399804308410452, 0.4181233316734022],\n",
       " [0.7625821030216905, 0.5214099038217975],\n",
       " [0.41088321525140814, 0.5374442681526889],\n",
       " [0.2705623137454708, 0.4333266215698163],\n",
       " [0.8272662882194327, 0.27185321763297077],\n",
       " [0.7273878130513135, 0.10024027644635503],\n",
       " [0.4977860316670397, 0.5803158538106875],\n",
       " [0.5766745754374724, 0.20703908355921719]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 1, 1, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Simple KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nearest neighbors for each test data are:\n",
      "\n",
      "[0.41088321525140814, 0.5374442681526889] \n",
      "\n",
      "[0.7625821030216905, 0.5214099038217975] \n",
      "\n",
      "[0.4977860316670397, 0.5803158538106875] \n",
      "\n",
      "------\n",
      "[0.3942564861172032, 0.1755924719507771] \n",
      "\n",
      "[0.07270586036662141, 0.19188086780745994] \n",
      "\n",
      "[0.5766745754374724, 0.20703908355921719] \n",
      "\n",
      "------\n",
      "[0.4977860316670397, 0.5803158538106875] \n",
      "\n",
      "[0.7625821030216905, 0.5214099038217975] \n",
      "\n",
      "[0.8272662882194327, 0.27185321763297077] \n",
      "\n",
      "------\n",
      "The labels of nearest neighbors are: [[1, 1, 0], [0, 0, 1], [0, 1, 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNN(X_training, Y_training, X_test)\n",
    "classifier.simple_KNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. kd-tree KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nearest neighbors for each sample are:\n",
      "\n",
      "[0.7625821030216905, 0.5214099038217975] \n",
      "\n",
      "[0.41088321525140814, 0.5374442681526889] \n",
      "\n",
      "[0.4977860316670397, 0.5803158538106875] \n",
      "\n",
      "------\n",
      "[0.07270586036662141, 0.19188086780745994] \n",
      "\n",
      "[0.3942564861172032, 0.1755924719507771] \n",
      "\n",
      "[0.5766745754374724, 0.20703908355921719] \n",
      "\n",
      "------\n",
      "[0.7625821030216905, 0.5214099038217975] \n",
      "\n",
      "[0.8272662882194327, 0.27185321763297077] \n",
      "\n",
      "[0.4977860316670397, 0.5803158538106875] \n",
      "\n",
      "------\n",
      "The labels of nearest neighbors are: [[1, 1, 1], [0, 0, 1], [1, 0, 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Construct kd-tree\n",
    "root = kdTree(X_training, Y_training).construct_kdTree()\n",
    "cls = KNN(X_training, Y_training, X_test)\n",
    "cls.kdTree_KNN(root, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference:\n",
    "- https://zhuanlan.zhihu.com/p/23966698"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
